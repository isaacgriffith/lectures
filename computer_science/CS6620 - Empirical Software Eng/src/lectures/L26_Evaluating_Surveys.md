---
author:
- Isaac Griffith
title: Evaluating Surveys
institute: |
  CS 6620

  Department of Informatics and Computer Science

  Idaho State University
fontsize: 12pt
cornerLogo: "images/spirit.png"
wideLogo: "images/wide.png"
lowerCornerLogo: "images/roar.eps"
...

# Introduction

To evaluate surveys we will use the checklist developed by Molleri et al. which considers the following phases of survey studies:

::: columns
:::: column

1. Research objectives
2. Study plan
3. Identify population
4. Sampling plan
5. Instrument design

::::
:::: column

6. Instrument validation
7. Participant recruitment
8. Response management
9. Data analysis
10. Reporting

::::
:::

# Research Objectives

* Are the research objectives expressed in measureable terms? E.g. as resaerch questions, or using the GQM approach.
* Is the research context defined? Does it consider a reasonable set of objectives?
* Is the need for survey research motivated (i.e. grounded on background and related studies)?

# Study Plan

* Is the survey process conducted based upon detailed procedures?
* Is there a reflection on the need to update the research plan?
* Are the roles and responsibilities of researchers and other stakeholders defined?

# Identify Population

* Is the population or the survey's target audience characterized (e.g. through audience analysis)?
* Is the size of the population stated? If it is not possible to gather this data, are statistic estimates of the population drawn?

# Sampling Plan

* Is the kind of sample (i.e. probabilistic, non-probabilistic) defined?
* Is the sampling process described, and the resulting sample size presented?
* Are the sources of sampling (e.g. particular databases or directories, open or restricted) defined? E.g. through a search plan.
* Are the strategies and criteria to select units (of observation, of analysis and search unit) stated? E.g. through a sampling frame.

# Instrument Design

* Is the type of instrument (i.e. self- or interviewer-administrated) defined?
* Is the instrument design process (acquisition, development, prototyping, versioning, reuse) described in the report?
* Are the demographic questions formulated according to the audience? If a stratification of the sample is planned, are the demographics adequate to characterize subsets of the participants?
* Has special care been taken to make the questions understandable by the respondents? E.g. through using a terminology familiar to the target population, or by providing a thesaurus.
* Has special care been taken to avoid intrusive and unethical questions? E.g. such biases may include questions that lead the respondent to a particular answer, or to expose personal data or behavior.

# Instrument Design

* Is the number and order of the questions taken into consideration?
* Is there a reflection on the type of responses (i.e. open-ended, close-ended, or a mix of both) required for the questions?
* If employing close-ended questions, are the standardized response formats (i.e. nominal, ordinal, interval or ratio) stated?
* Is there a reflection on the adoption of additional sources for data collection? E.g. through the participant's profile or supporting literature?

# Instrument Validation

* Is the validation process of the survey instrument detailed? E.g. through piloting, pre-test, retest, focus groups, experiments, expert or non-expert reviews.
* Is the instrument measuring what is intended? Are the questionnaire items mapped to the research question(s)?
* In the case of an electronic or online questionnaire, is the usability evaluated? E.g. questionnaire navigation, instructions of use, option to resume answering, progress indicator, required/non-inputs, aesthetics, and layout.
* Are the results of the instrument validation discussed?

# Participant Recruitment

* Are the strategies to select participants implemented? E.g. through invitations, authorization codes, self-recruitment, or snowballing.
* Are the ancillary documents (e.g. invitation, cover an thank you letter) provided? If they were not produced, are the reasons for that discussed and convincing?
* If rewards or incentives to respondents are provided, are the reasons and implications (e.g. ethical concerns, biases) discussed?

# Response Management

* Are the responses monitored? E.g. response rate, non-responsiveness, and drop-out questions. In case of inadequate response rate, the reasons for non-responses and drop-out items were investigated?
* Is there any action to be taken in case of non-responses (e.g. reminders)? If reminders are employed, is the process for selecting and inviting new participants described? Moreover, are the implications of reminders discussed? I.e. changes in the sample size are likely to impact the heterogeneity and generalizability of data.

# Data Analysis

* Is the data validated prior to analysis? E.g. through checking inconsistent, incomplete and missing values.
* Is the method for data analysis specified? Are the steps of the analysis process described? Are they suitable for the response formats collected?
* If statistical analysis is employed, is the hypothesis testing process documented and the standardized responses presented? E.g. through tables, graphs, charts and plots.
* If using qualitative synthesis (e.g. meta-ethnography, thematic or content analysis), is it clear how the categories/themes were derived from the data?
* If a stratified sample is defined, are the data analyzed according to demographics? Are there meaningful comparisons drawn from them?

# Reporting

* Are the instrument and ancillary documents accessible (e.g. URL link, external reference, appendix) to readers? If not, are the reasons for that discussed and convincing? If data resulting from the survey were disclosure, were anonymity and confidentiality of data discussed?
* Has a discussion of both positive and negative findings been demonstrated? Are the discussion addressing the research question(s) or hypothesis? Does the discussion take into consideration the generalization of the findings?
* Are the results of the assessment checklist reported? Are limitations of the study (e.g. threats to validity) discussed?
* Are the conclusions justified by the results? Furthermore, are the implications and potential use of the results discussed?

#

\centering
\includegraphics[scale=.40]{images/questions.png}

\Huge \textbf{Are there any questions?}
